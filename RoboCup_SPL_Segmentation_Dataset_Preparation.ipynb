{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RoboCup SPL Segmentation Dataset Preparation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMz/vmU/MAzL7e0JbNJSRDH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/piebro/RoboCup-SPL-Segmentation-Dataset/blob/master/RoboCup_SPL_Segmentation_Dataset_Preparation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cHTAbBOG-EG",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "# @title get dataset from Kaggle\n",
        "! pip install -q kaggle\n",
        "\n",
        "# upload kaggle.json api key: https://www.kaggle.com/docs/api\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "! mkdir -p ~/.kaggle \n",
        "! mv kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download pietbroemmel/naodevils-segmentation-upper-camera"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gokc5o1VJOR-",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "# @title unzip data\n",
        "!unzip -q naodevils-segmentation-upper-camera.zip -d dataset "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b82B_a5BJTGI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "cellView": "form",
        "outputId": "54c7a824-9f62-45b7-ab06-1d59583c2f18"
      },
      "source": [
        "# @title install dependancies\n",
        "!pip install -q imantics"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for imantics (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JDY7x45JOVE",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "# @title declare paths\n",
        "dataset_root_path = \"dataset\"\n",
        "anns_manual_all = \"annotations/manual_all.json\"\n",
        "anns_autolabel_all = \"annotations/autolabel_all.json\"\n",
        "\n",
        "anns_manual_pergame_dir = \"annotations/manual_pergame\"\n",
        "anns_autolabel_pergame_dir = \"annotations/autolabel_pergame\"\n",
        "\n",
        "anns_manual_train = \"annotations/manual_train.json\"\n",
        "anns_manual_val = \"annotations/manual_val.json\"\n",
        "\n",
        "anns_autolabel_train = \"annotations/autolabel_train.json\"\n",
        "anns_autolabel_and_manual_train = \"annotations/autolabel_and_manual_train.json\"\n",
        "\n",
        "categories=[\"line\",\"ball\",\"robot\",\"centercircle\",\"goal\",\"penaltycross\"]\n",
        "class_id_to_color = [\n",
        "  [0, 0, 0],\n",
        "  [255,0,0],\n",
        "  [0,255,0],\n",
        "  [0,0,255],\n",
        "  [122,122,0],\n",
        "  [0,122,122],\n",
        "  [122,0,122]\n",
        "]"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdcViuZkJ4pH",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "# @title COCO Dataset Util Functions\n",
        "import os\n",
        "import glob\n",
        "\n",
        "import json\n",
        "import sys\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import imantics\n",
        "from pycocotools.coco import COCO\n",
        "\n",
        "def save_combined_annotation_json(coco_json_paths, output_json_path, new_categories):\n",
        "  filename_to_annotations = {}\n",
        "\n",
        "  for coco_json in coco_json_paths:\n",
        "    coco = COCO(coco_json)\n",
        "\n",
        "    id_to_new_id = {}\n",
        "    for cat_id in coco.getCatIds():\n",
        "      cat_data = coco.loadCats(cat_id)[0]\n",
        "      new_cat_id = new_categories.index(cat_data[\"name\"]) + 1\n",
        "      id_to_new_id[cat_id] = new_cat_id\n",
        "\n",
        "    for img_id in coco.imgs.keys():\n",
        "      annotations = []\n",
        "      for ann_old in coco.loadAnns(coco.getAnnIds(img_id)):\n",
        "        annotation = {\n",
        "          \"category_id\": id_to_new_id[ann_old[\"category_id\"]],\n",
        "          \"segmentation\": ann_old[\"segmentation\"],\n",
        "          \"bbox\": ann_old[\"bbox\"],\n",
        "        }\n",
        "        annotations.append(annotation)\n",
        "      \n",
        "      filename = coco.loadImgs(img_id)[0][\"file_name\"]\n",
        "      \n",
        "      if filename in filename_to_annotations:\n",
        "        filename_to_annotations[filename].extend(annotations)\n",
        "      else:\n",
        "        filename_to_annotations[filename] = annotations\n",
        "\n",
        "  filename_annotations = []\n",
        "  for filename, annotations in filename_to_annotations.items():\n",
        "    filename_annotations.append({\n",
        "      \"filename\": filename,\n",
        "      \"annotations\": annotations\n",
        "    })\n",
        "\n",
        "  coco_json = filename_annotations_list_to_coco_json(filename_annotations, new_categories)\n",
        "  with open(output_json_path, 'w') as outfile:\n",
        "    json.dump(coco_json, outfile)\n",
        "\n",
        "\n",
        "def get_mask_handle_occlusion(annotation, height, width):\n",
        "  count = len(annotation)\n",
        "  mask = np.zeros([height, width, count], dtype=np.uint8)\n",
        "  \n",
        "  \n",
        "  seg_list_robot_and_ball = []\n",
        "  seg_list_goal = []\n",
        "  seg_list_rest = []\n",
        "  # ids: line:1, ball:2, robot:3, centercircle:4, goal:5, penaltycross:6\n",
        "  # first draw order: goal, line, centercircle, penaltycross, [robot,ball]\n",
        "  for shape in annotation:\n",
        "    category_id = shape[\"category_id\"]\n",
        "    segmentations  = shape[\"segmentation\"]\n",
        "\n",
        "    if category_id == 2 or category_id == 3:\n",
        "        seg_list_robot_and_ball.append((category_id, segmentations))\n",
        "    elif category_id == 6:\n",
        "        seg_list_goal.append((category_id, segmentations))\n",
        "    else:\n",
        "        seg_list_rest.append((category_id, segmentations))\n",
        "  \n",
        "\n",
        "  seg_list = []\n",
        "  seg_list.extend(seg_list_goal)\n",
        "  seg_list.extend(sorted(seg_list_rest, key=lambda x: x[0]))\n",
        "  seg_list.extend(seg_list_robot_and_ball)\n",
        "  \n",
        "  category_id_list = []\n",
        "  for i, (category_id, segmentations) in enumerate(seg_list):\n",
        "    category_id_list.append(category_id)\n",
        "\n",
        "    pts = [\n",
        "      np\n",
        "      .array(anno)\n",
        "      .reshape(-1, 2)\n",
        "      .round()\n",
        "      .astype(int)\n",
        "      for anno in segmentations\n",
        "      ]\n",
        "        \n",
        "    img = mask[:, :, i:i+1].copy()\n",
        "    cv2.fillPoly(img, pts, 1)\n",
        "    mask[:, :, i:i+1] = img\n",
        "    \n",
        "  # Handle occlusions\n",
        "  if(mask.shape[2] > 0): # if at least one mask is there\n",
        "    occlusion = np.logical_not(mask[:, :, -1]).astype(np.uint8)\n",
        "    for i in range(count-2, -1, -1):\n",
        "        mask[:, :, i] = mask[:, :, i] * occlusion\n",
        "        occlusion = np.logical_and(occlusion, np.logical_not(mask[:, :, i]))\n",
        "\n",
        "  return mask.astype(np.bool), np.array(category_id_list).astype(np.int32)\n",
        "\n",
        "\n",
        "def save_non_overlapping_annotations_json(json_path, save_json_path):\n",
        "  coco = COCO(json_path)\n",
        "  with open(json_path) as json_file:\n",
        "    coco_json = json.load(json_file)\n",
        "\n",
        "  coco_json_new = {}\n",
        "  coco_json_new[\"categories\"] = coco_json[\"categories\"]\n",
        "  coco_json_new[\"images\"] = coco_json[\"images\"]\n",
        "  \n",
        "  new_annotations = []\n",
        "  for img_count, img_id in enumerate(coco.imgs.keys()):\n",
        "\n",
        "    annotations = coco.loadAnns(coco.getAnnIds(img_id))\n",
        "    mask = get_mask_handle_occlusion(annotations, width=640, height=480)\n",
        "    \n",
        "    for i, class_id in enumerate(mask[1]):\n",
        "      im_mask = imantics.Mask(mask[0][:,:,i])\n",
        "      polygons = im_mask.polygons()\n",
        "      polygons_new = []\n",
        "      for poly in polygons:\n",
        "        polygons_new.append(poly.tolist())\n",
        "\n",
        "      new_annotation = {\n",
        "          \"id\":len(new_annotations),\n",
        "          \"image_id\": img_id,\n",
        "          \"category_id\": int(class_id),\n",
        "          \"segmentation\": polygons_new,\n",
        "          \"bbox\": list(im_mask.bbox().bbox()),\n",
        "          'iscrowd': False,\n",
        "          'isbbox': False\n",
        "      }\n",
        "      new_annotations.append(new_annotation)\n",
        "      \n",
        "      sys.stdout.write('\\rremoved overlapping for '+str(img_count+1)+' / '+str(len(coco.imgs.keys()))+' images')\n",
        "      sys.stdout.flush()\n",
        "  \n",
        "  print(\"\")\n",
        "    \n",
        "  coco_json_new[\"annotations\"] = new_annotations\n",
        "  with open(save_json_path, 'w') as outfile:\n",
        "    json.dump(coco_json_new, outfile)\n",
        "\n",
        "\n",
        "def save_train_val_annotations_json(json_path, train_json_path, val_json_path, val_size, shuffel_seed=42):\n",
        "  coco = COCO(json_path)\n",
        "  img_ids = sorted(coco.imgs.keys())\n",
        "\n",
        "  np.random.seed(shuffel_seed)\n",
        "  np.random.shuffle(img_ids)\n",
        "\n",
        "  seperate_index = round(len(img_ids)*val_size)\n",
        "  img_ids_val = img_ids[:seperate_index]\n",
        "  img_ids_train = img_ids[seperate_index:]\n",
        "\n",
        "  with open(json_path) as json_file:\n",
        "    categories_json = json.load(json_file)[\"categories\"]\n",
        "\n",
        "  for img_ids, save_path in [[img_ids_val, val_json_path], [img_ids_train, train_json_path]]:\n",
        "    save_json = {\n",
        "        \"images\":[],\n",
        "        \"categories\":categories_json,\n",
        "        \"annotations\":[]\n",
        "    }\n",
        "\n",
        "    for img_id in img_ids:\n",
        "      save_json[\"images\"].append(coco.loadImgs(img_id)[0])\n",
        "      save_json[\"annotations\"].extend(coco.loadAnns(coco.getAnnIds(img_id)))\n",
        "\n",
        "    with open(save_path, 'w') as outfile:\n",
        "      json.dump(save_json, outfile)\n",
        "\n",
        "\n",
        "def filename_annotations_list_to_coco_json(filename_annotations_list, categories):\n",
        "  images = []\n",
        "  annotations = []\n",
        "  categories_json = []\n",
        "\n",
        "  for i, cat_name in enumerate(categories):\n",
        "    categories_json.append({\"id\":i+1, \"name\":cat_name})\n",
        "\n",
        "  for img_id, filename_annotations in enumerate(filename_annotations_list):\n",
        "    images.append({\n",
        "        \"id\": img_id,\n",
        "        \"path\": filename_annotations[\"filename\"],\n",
        "        \"file_name\": filename_annotations[\"filename\"],\n",
        "    })\n",
        "\n",
        "    for annotation in filename_annotations[\"annotations\"]:\n",
        "      annotation[\"id\"] = len(annotations)+1\n",
        "      annotation[\"image_id\"] = img_id\n",
        "      annotations.append(annotation)\n",
        "\n",
        "  return {\n",
        "      \"images\":images,\n",
        "      \"annotations\":annotations,\n",
        "      \"categories\":categories_json\n",
        "  }\n",
        "\n",
        "def split_annotations_per_games(json_path, annotations_folder):\n",
        "    if os.path.isdir(annotations_folder) and len(os.listdir(annotations_folder)) != 0:\n",
        "        print(\"The folder is not empty\")\n",
        "        return\n",
        "    os.mkdir(annotations_folder)\n",
        "  \n",
        "    coco = COCO(json_path)\n",
        "    with open(json_path) as json_file:\n",
        "        coco_json = json.load(json_file)\n",
        "\n",
        "    new_jsons = {}\n",
        "\n",
        "    for img_id in coco.imgs.keys():\n",
        "        img_data = coco.loadImgs(img_id)[0]\n",
        "        filename = img_data[\"file_name\"]\n",
        "        game_name = \"_\".join(filename.split(\"_\")[1:3])\n",
        "        if game_name not in new_jsons:\n",
        "            new_jsons[game_name] = {\n",
        "              \"categories\": coco_json[\"categories\"],\n",
        "              \"images\": [],\n",
        "              \"annotations\": []\n",
        "            }\n",
        "    \n",
        "        new_jsons[game_name][\"images\"].append(img_data)\n",
        "        new_jsons[game_name][\"annotations\"].extend(coco.loadAnns(coco.getAnnIds(img_id)))\n",
        "\n",
        "    for key, value in new_jsons.items():\n",
        "        save_json_path = os.path.join(annotations_folder, key + \".json\")\n",
        "        print(\"saved\", key, \"at\", save_json_path, \"with\", len(value[\"images\"]), \"images and\", len(value[\"annotations\"]), \"annotations\")\n",
        "        with open(save_json_path, 'w') as outfile:\n",
        "            json.dump(value, outfile)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1iYi2p6JOZm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "64714551-0ebf-481c-e5dc-b85983fa9343"
      },
      "source": [
        "os.mkdir(\"annotations\")\n",
        "raw_manual_annotations_root_path = os.path.join(dataset_root_path, \"raw_manual_annotations\")\n",
        "json_filenames = [\"upper_00000_00500.json\", \"upper_00500_01000.json\", \"upper_01000_01500.json\"]\n",
        "json_paths = []\n",
        "for json_filename in json_filenames:\n",
        "    json_paths.append(os.path.join(raw_manual_annotations_root_path, json_filename))\n",
        "\n",
        "save_combined_annotation_json(json_paths, anns_manual_all, categories)\n",
        "save_non_overlapping_annotations_json(anns_manual_all, anns_manual_all)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.07s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.06s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.16s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.07s)\n",
            "creating index...\n",
            "index created!\n",
            "removed overlapping for 1179 / 1179 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFedTZyxJOek",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "6cf7f298-429c-4106-b0ac-7ff93aa0b017"
      },
      "source": [
        "split_annotations_per_games(anns_manual_all, anns_manual_pergame_dir)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.35s)\n",
            "creating index...\n",
            "index created!\n",
            "saved GermanOpen2019_HULKs at annotations/manual_pergame/GermanOpen2019_HULKs.json with 464 images and 2624 annotations\n",
            "saved RoboCup2019_rUNSWift at annotations/manual_pergame/RoboCup2019_rUNSWift.json with 326 images and 1505 annotations\n",
            "saved RoboCup2019_BandB at annotations/manual_pergame/RoboCup2019_BandB.json with 233 images and 1427 annotations\n",
            "saved RoboCup2019_Team-Team at annotations/manual_pergame/RoboCup2019_Team-Team.json with 151 images and 786 annotations\n",
            "saved RoboCup2019_HTWK-Leipzig at annotations/manual_pergame/RoboCup2019_HTWK-Leipzig.json with 5 images and 14 annotations\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMNVG5e8JOcq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "9124d863-36c5-41dd-f75f-c8adb16465cf"
      },
      "source": [
        "train_manual_paths = [\n",
        "    \"annotations/manual_pergame/GermanOpen2019_HULKs.json\",\n",
        "    \"annotations/manual_pergame/RoboCup2019_rUNSWift.json\",\n",
        "    \"annotations/manual_pergame/RoboCup2019_BandB.json\",\n",
        "    \"annotations/manual_pergame/RoboCup2019_HTWK-Leipzig.json\",\n",
        "]\n",
        "val_manual_paths = [\n",
        "    \"annotations/manual_pergame/RoboCup2019_Team-Team.json\",\n",
        "]\n",
        "save_combined_annotation_json(train_manual_paths, anns_manual_train, categories)\n",
        "save_combined_annotation_json(val_manual_paths, anns_manual_val, categories)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.14s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.09s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.07s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.04s)\n",
            "creating index...\n",
            "index created!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqncnpQVJOX9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "f8aae5f3-6e92-4872-ea5b-44206cd97d5f"
      },
      "source": [
        "raw_autolabel_annotations_root_path = os.path.join(dataset_root_path, \"raw_autolabel_annotations\")\n",
        "join_auto_label_paths = [\n",
        "    os.path.join(raw_autolabel_annotations_root_path, \"auto_label_br.json\"),\n",
        "    os.path.join(raw_autolabel_annotations_root_path, \"auto_label_lcgp.json\")\n",
        "]\n",
        "\n",
        "save_combined_annotation_json(join_auto_label_paths, anns_autolabel_all, categories)\n",
        "save_non_overlapping_annotations_json(anns_autolabel_all, anns_autolabel_all)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=2.67s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=2.92s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=3.40s)\n",
            "creating index...\n",
            "index created!\n",
            "removed overlapping for 8821 / 8821 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jytDRQqrKxkG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "be7f4cf0-ca5e-4d84-981e-166a7c121724"
      },
      "source": [
        "split_annotations_per_games(anns_autolabel_all, anns_autolabel_pergame_dir)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=3.27s)\n",
            "creating index...\n",
            "index created!\n",
            "saved RoboCup2019_Dutch-Nao at annotations/autolabel_pergame/RoboCup2019_Dutch-Nao.json with 1294 images and 8876 annotations\n",
            "saved RoboCup2019_TJark at annotations/autolabel_pergame/RoboCup2019_TJark.json with 1127 images and 7803 annotations\n",
            "saved RoboCup2019_HULKs at annotations/autolabel_pergame/RoboCup2019_HULKs.json with 3503 images and 23619 annotations\n",
            "saved RoboCup2019_SwiftArk at annotations/autolabel_pergame/RoboCup2019_SwiftArk.json with 908 images and 7993 annotations\n",
            "saved RoboCup2019_NTU-RoboPal at annotations/autolabel_pergame/RoboCup2019_NTU-RoboPal.json with 1168 images and 8058 annotations\n",
            "saved GermanOpen2019_HULKs at annotations/autolabel_pergame/GermanOpen2019_HULKs.json with 135 images and 852 annotations\n",
            "saved RoboCup2019_HTWK-Leipzig at annotations/autolabel_pergame/RoboCup2019_HTWK-Leipzig.json with 500 images and 2862 annotations\n",
            "saved RoboCup2019_BandB at annotations/autolabel_pergame/RoboCup2019_BandB.json with 64 images and 491 annotations\n",
            "saved RoboCup2019_Team-Team at annotations/autolabel_pergame/RoboCup2019_Team-Team.json with 44 images and 257 annotations\n",
            "saved RoboCup2019_rUNSWift at annotations/autolabel_pergame/RoboCup2019_rUNSWift.json with 78 images and 413 annotations\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1f3USnKKxmt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "325ee96f-7d0b-4e9a-a28a-3764de379fa4"
      },
      "source": [
        "train_autolabel_paths = [\n",
        "    \"annotations/autolabel_pergame/RoboCup2019_HULKs.json\",\n",
        "    \"annotations/autolabel_pergame/RoboCup2019_NTU-RoboPal.json\",\n",
        "    \"annotations/autolabel_pergame/RoboCup2019_TJark.json\",\n",
        "    \"annotations/autolabel_pergame/RoboCup2019_HTWK-Leipzig.json\",\n",
        "    \"annotations/autolabel_pergame/RoboCup2019_Dutch-Nao.json\",\n",
        "]\n",
        "save_combined_annotation_json(train_autolabel_paths, anns_autolabel_train, categories)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=1.00s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.55s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.35s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.13s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.65s)\n",
            "creating index...\n",
            "index created!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Dc0TzyxKxp4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "688c9f92-44bf-4d4a-bc8a-c4b129259cce"
      },
      "source": [
        "train_autolabel_and_manual_paths = [\n",
        "    \"annotations/autolabel_train.json\",\n",
        "    \"annotations/manual_train.json\",\n",
        "]\n",
        "save_combined_annotation_json(train_autolabel_and_manual_paths, anns_autolabel_and_manual_train, categories)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=2.69s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.30s)\n",
            "creating index...\n",
            "index created!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vnq5HItCK4jg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "cellView": "form",
        "outputId": "ca500210-2ea4-40d7-9382-a69b0d1b6320"
      },
      "source": [
        "# @title Analyse Dataset\n",
        "\n",
        "def analyse_annotations(json_path):\n",
        "    info = {}\n",
        "    info[\"file_path\"] = json_path\n",
        "    coco = COCO(json_path)\n",
        "    img_ids = coco.imgs.keys()\n",
        "    info[\"image_count\"] = len(img_ids)\n",
        "    anns_ids = coco.anns.keys()\n",
        "    info[\"annotation_count\"] = len(anns_ids)\n",
        "\n",
        "    cat_id_to_name = {}\n",
        "    for _, cat in coco.cats.items():\n",
        "        cat_id_to_name[cat['id']] = cat['name']\n",
        "\n",
        "    cat_counts = {}\n",
        "    for ann_id in anns_ids:\n",
        "        cat_id = coco.anns[ann_id][\"category_id\"]\n",
        "        if cat_id not in cat_counts:\n",
        "            cat_counts[cat_id] = 0\n",
        "        else:\n",
        "            cat_counts[cat_id] += 1\n",
        "\n",
        "    for cat_id, count in cat_counts.items():\n",
        "        cat_name = cat_id_to_name[cat_id]\n",
        "        info[cat_name + \"_counts\"] = count\n",
        "        info[cat_name + \"_counts_percent\"] = round(count/info[\"annotation_count\"]*100)/100\n",
        "  \n",
        "    return info\n",
        "\n",
        "def analyse_annotations_list(list_of_annotations_jsons):\n",
        "    infos = {}\n",
        "    for anns_file in list_of_annotations_jsons:\n",
        "        infos[anns_file] = analyse_annotations(anns_file)\n",
        "    return infos\n",
        "\n",
        "def analyse_annotations_list_to_text(list_of_annotations_jsons):\n",
        "    infos = analyse_annotations_list(list_of_annotations_jsons)\n",
        "    text_array = []\n",
        "    for _, info in infos.items():\n",
        "        text_array.append(annotation_info_to_text(info, categories))\n",
        "    return \"\\n\\n\".join(text_array)\n",
        "\n",
        "def annotation_info_to_text(info, categories):\n",
        "    for category in categories:\n",
        "        category_counts = category + \"_counts\"\n",
        "        if category_counts not in info:\n",
        "            info[category_counts] = None\n",
        "        \n",
        "    return \"\\n\".join([\n",
        "        f'filepath: {info[\"file_path\"]}',\n",
        "        f'images: {info[\"image_count\"]}, annotations: {info[\"annotation_count\"]}',\n",
        "        f'lines: {info[\"line_counts\"]}, balls: {info[\"ball_counts\"]}, robots: {info[\"robot_counts\"]}, centercircles: {info[\"centercircle_counts\"]}, goals: {info[\"goal_counts\"]}, penaltycrosses: {info[\"penaltycross_counts\"]}'\n",
        "    ])\n",
        "\n",
        "\n",
        "all_anns_files = glob.glob(\"annotations/*.json\") + glob.glob(\"annotations/**/*.json\")\n",
        "text = analyse_annotations_list_to_text(all_anns_files)\n",
        "\n",
        "with open(\"annotations/overview.txt\", \"w\") as f:\n",
        "    f.write(text)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=2.97s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=2.73s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.27s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.33s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=3.32s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.26s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.32s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.41s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.12s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.40s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=1.12s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.06s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.09s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.15s)\n",
            "creating index...\n",
            "index created!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RW8ic72JK4gM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "a5b32fc0-9c9e-4c79-daf5-67cd64d64625"
      },
      "source": [
        "!cd \"annotations\"; zip -r ../annotations.zip *\n",
        "!du annotations.zip"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: autolabel_all.json (deflated 72%)\n",
            "  adding: autolabel_and_manual_train.json (deflated 71%)\n",
            "  adding: autolabel_pergame/ (stored 0%)\n",
            "  adding: autolabel_pergame/RoboCup2019_BandB.json (deflated 72%)\n",
            "  adding: autolabel_pergame/RoboCup2019_SwiftArk.json (deflated 72%)\n",
            "  adding: autolabel_pergame/RoboCup2019_Team-Team.json (deflated 72%)\n",
            "  adding: autolabel_pergame/RoboCup2019_TJark.json (deflated 72%)\n",
            "  adding: autolabel_pergame/RoboCup2019_rUNSWift.json (deflated 71%)\n",
            "  adding: autolabel_pergame/RoboCup2019_Dutch-Nao.json (deflated 72%)\n",
            "  adding: autolabel_pergame/RoboCup2019_HTWK-Leipzig.json (deflated 72%)\n",
            "  adding: autolabel_pergame/GermanOpen2019_HULKs.json (deflated 72%)\n",
            "  adding: autolabel_pergame/RoboCup2019_NTU-RoboPal.json (deflated 72%)\n",
            "  adding: autolabel_pergame/RoboCup2019_HULKs.json (deflated 72%)\n",
            "  adding: autolabel_train.json (deflated 71%)\n",
            "  adding: manual_all.json (deflated 72%)\n",
            "  adding: manual_pergame/ (stored 0%)\n",
            "  adding: manual_pergame/RoboCup2019_BandB.json (deflated 72%)\n",
            "  adding: manual_pergame/RoboCup2019_Team-Team.json (deflated 72%)\n",
            "  adding: manual_pergame/RoboCup2019_rUNSWift.json (deflated 71%)\n",
            "  adding: manual_pergame/RoboCup2019_HTWK-Leipzig.json (deflated 70%)\n",
            "  adding: manual_pergame/GermanOpen2019_HULKs.json (deflated 72%)\n",
            "  adding: manual_train.json (deflated 71%)\n",
            "  adding: manual_val.json (deflated 71%)\n",
            "  adding: overview.txt (deflated 78%)\n",
            "124836\tannotations.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BZxEcB9K4dj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}